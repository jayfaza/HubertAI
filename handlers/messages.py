# handlers/messages.py
# –û–±—Ä–∞–±–æ—Ç—á–∏–∫–∏ —Å–æ–æ–±—â–µ–Ω–∏–π ‚Äî Reply-–∫–ª–∞–≤–∏–∞—Ç—É—Ä–∞ + –º–µ–Ω—é –≤—ã–±–æ—Ä–∞ –º–æ–¥–µ–ª–µ–π (inline),
# –ø–∞–≥–∏–Ω–∞—Ü–∏—è, —Å–º–µ–Ω–∞ system prompt, –æ—á–∏—Å—Ç–∫–∞ –∏—Å—Ç–æ—Ä–∏–∏, –æ—Å–Ω–æ–≤–Ω–æ–π —á–∞—Ç —Å–æ —Å—Ç—Ä–∏–º–∏–Ω–≥–æ–º.
from aiogram import F
from aiogram.types import ContentType

from aiogram import Router, types
from aiogram.filters import Command
from aiogram.types import (
    ReplyKeyboardMarkup,
    KeyboardButton,
    InlineKeyboardMarkup,
    InlineKeyboardButton,
)
import urllib.parse
import math
import logging
import asyncio

from storage import get_user
from services.ollama_client import generate_stream, get_models

router = Router()

# –ü–æ—Å—Ç–æ—è–Ω–Ω–∞—è –∫–ª–∞–≤–∏–∞—Ç—É—Ä–∞ –≤–Ω–∏–∑—É
main_keyboard = ReplyKeyboardMarkup(
    keyboard=[
        [KeyboardButton(text="üìã –ú–æ–¥–µ–ª—å"), KeyboardButton(text="üéõ Prompt")],
        [KeyboardButton(text="üßπ –û—á–∏—Å—Ç–∏—Ç—å")],
    ],
    resize_keyboard=True,
)

PAGE_SIZE = 8  # —Å–∫–æ–ª—å–∫–æ –º–æ–¥–µ–ª–µ–π –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü—É


# /start
@router.message(Command("start"))
async def cmd_start(message: types.Message):
    await message.answer(
        f"–ü—Ä–∏–≤–µ—Ç—Å—Ç–≤—É—é, –≤–∞—à–µ –±–ª–∞–≥–æ—Ä–æ–¥–∏–µ! –Ø - –•—å—é–±–µ—Ä—Ç –±–æ—Ç, —Å–æ–¥–µ—Ä–∂a—â–∏–π –≤ —Å–µ–±–µ –∫—É—á—É –Ω–µ–π—Ä–æ—Å–µ—Ç–µ–π –æ—Å–Ω–æ–≤–∞–Ω—ã—Ö –Ω–∞ –æ–±—â–µ–Ω–∏–∏. –ï—Å–ª–∏ –≤—ã —á—É–≤—Ç–≤—É–µ—Ç–µ —Å–µ–±—è –æ–¥–∏–Ω–æ–∫–∏–º, —Ç–æ –º–æ—è —Ü–µ–ª—å —Å–∫—Ä–∞—Å–∏—Ç—å –≤–∞—à–µ –æ–¥–∏–Ω–æ—á–µ—Å—Ç–≤–æ!",
        reply_markup=main_keyboard,
    )


# Reply-–∫–Ω–æ–ø–∫–∞ "üìã –ú–æ–¥–µ–ª—å"
@router.message(lambda m: m.text == "üìã –ú–æ–¥–µ–ª—å")
async def on_choose_model(message: types.Message):
    models = await get_models()
    if not models:
        await message.answer("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π. –ü—Ä–æ–≤–µ—Ä—å Ollama.")
        return

    keyboard = build_models_keyboard(models, page=0)
    await message.answer("–í—ã–±–µ—Ä–∏ –º–æ–¥–µ–ª—å:", reply_markup=keyboard)


# –ö–æ–Ω—Å—Ç—Ä—É–∫—Ç–æ—Ä inline-–∫–ª–∞–≤–∏–∞—Ç—É—Ä—ã –¥–ª—è —Å—Ç—Ä–∞–Ω–∏—Ü
def build_models_keyboard(models, page: int) -> InlineKeyboardMarkup:
    total_pages = max(1, math.ceil(len(models) / PAGE_SIZE))
    print(f"total_pages: {total_pages}")
    page = max(0, min(page, total_pages - 1))
    print(f"page: {page}")

    start = page * PAGE_SIZE
    print(f"start: {start}")
    end = start + PAGE_SIZE
    print(f"end: {end}")
    slice_models = models[start:end]
    print(f"slice_models: {slice_models}")

    rows = []
    for name in slice_models:
        encoded = urllib.parse.quote_plus(name)
        rows.append(
            [InlineKeyboardButton(text=name, callback_data=f"setmodel:{encoded}")]
        )

    nav = []
    if page > 0:
        nav.append(
            InlineKeyboardButton(
                text="‚¨ÖÔ∏è –ù–∞–∑–∞–¥", callback_data=f"models_page:{page - 1}"
            )
        )
    if page < total_pages - 1:
        nav.append(
            InlineKeyboardButton(
                text="–í–ø–µ—Ä–µ–¥ ‚û°Ô∏è", callback_data=f"models_page:{page + 1}"
            )
        )
    if nav:
        rows.append(nav)

    rows.append([InlineKeyboardButton(text="–ó–∞–∫—Ä—ã—Ç—å ‚ùå", callback_data="models_close")])

    return InlineKeyboardMarkup(inline_keyboard=rows)


# –ü–µ—Ä–µ—Ö–æ–¥ –ø–æ —Å—Ç—Ä–∞–Ω–∏—Ü–∞–º
@router.callback_query(lambda c: c.data and c.data.startswith("models_page:"))
async def on_models_page(callback: types.CallbackQuery):
    await callback.answer()
    try:
        page = int(callback.data.split(":", 1)[1])
    except Exception:
        page = 0

    models = await get_models()
    if not models:
        try:
            await callback.message.edit_text("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π.")
        except Exception:
            await callback.message.answer("‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Å–ø–∏—Å–æ–∫ –º–æ–¥–µ–ª–µ–π.")
        return

    keyboard = build_models_keyboard(models, page=page)
    try:
        await callback.message.edit_text("–í—ã–±–µ—Ä–∏ –º–æ–¥–µ–ª—å:", reply_markup=keyboard)
    except Exception:
        await callback.message.answer("–í—ã–±–µ—Ä–∏ –º–æ–¥–µ–ª—å:", reply_markup=keyboard)


# –í—ã–±–æ—Ä –º–æ–¥–µ–ª–∏
@router.callback_query(lambda c: c.data and c.data.startswith("setmodel:"))
async def on_set_model(callback: types.CallbackQuery):
    await callback.answer()
    try:
        encoded = callback.data.split(":", 1)[1]
        model_name = urllib.parse.unquote_plus(encoded)
    except Exception:
        try:
            await callback.message.edit_text("‚ùå –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏–º—è –º–æ–¥–µ–ª–∏.")
        except Exception:
            await callback.message.answer("‚ùå –ù–µ–ø—Ä–∞–≤–∏–ª—å–Ω–æ–µ –∏–º—è –º–æ–¥–µ–ª–∏.")
        return

    user = get_user(callback.from_user.id)
    user["model"] = model_name

    try:
        await callback.message.edit_text(f"‚úÖ –ú–æ–¥–µ–ª—å –∏–∑–º–µ–Ω–µ–Ω–∞ –Ω–∞: {model_name}")
    except Exception:
        await callback.message.answer(f"‚úÖ –ú–æ–¥–µ–ª—å –∏–∑–º–µ–Ω–µ–Ω–∞ –Ω–∞: {model_name}")


# –ó–∞–∫—Ä—ã—Ç—å –º–µ–Ω—é –º–æ–¥–µ–ª–µ–π
@router.callback_query(lambda c: c.data == "models_close")
async def on_models_close(callback: types.CallbackQuery):
    await callback.answer()
    try:
        await callback.message.delete()
    except Exception:
        try:
            await callback.message.edit_text("–ú–µ–Ω—é –∑–∞–∫—Ä—ã—Ç–æ.")
        except Exception:
            pass


# Reply-–∫–Ω–æ–ø–∫–∞ "üéõ Prompt"
@router.message(lambda m: m.text == "üéõ Prompt")
async def on_change_prompt(message: types.Message):
    user = get_user(message.from_user.id)
    user["waiting_for_prompt"] = True
    await message.answer("‚úçÔ∏è –û—Ç–ø—Ä–∞–≤—å –Ω–æ–≤—ã–π system prompt –æ–¥–Ω–∏–º —Å–æ–æ–±—â–µ–Ω–∏–µ–º.")


# Reply-–∫–Ω–æ–ø–∫–∞ "üßπ –û—á–∏—Å—Ç–∏—Ç—å"
@router.message(lambda m: m.text == "üßπ –û—á–∏—Å—Ç–∏—Ç—å")
async def on_clear_history(message: types.Message):
    user = get_user(message.from_user.id)
    user["history"] = []
    await message.answer("üßπ –ò—Å—Ç–æ—Ä–∏—è –æ—á–∏—â–µ–Ω–∞.")


@router.message(F.content_type == ContentType.VOICE)
async def handle_voice(message: types.Message):
    user = get_user(message.from_user.id)

    # –ï—Å–ª–∏ –∂–¥—ë–º prompt ‚Äî –∏–≥–Ω–æ—Ä–∏—Ä—É–µ–º –≥–æ–ª–æ—Å–æ–≤—ã–µ (–∏–ª–∏ –º–æ–∂–Ω–æ –∞–¥–∞–ø—Ç–∏—Ä–æ–≤–∞—Ç—å)
    if user.get("waiting_for_prompt"):
        await message.answer("‚ö†Ô∏è –û–∂–∏–¥–∞—é —Ç–µ–∫—Å—Ç–æ–≤—ã–π system prompt.")
        return

    placeholder = await message.answer("üé§ –†–∞—Å–ø–æ–∑–Ω–∞—é –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ...")

    try:
        # –°–∫–∞—á–∏–≤–∞–µ–º —Ñ–∞–π–ª
        file_id = message.voice.file_id
        file = await message.bot.get_file(file_id)
        downloaded_file = await message.bot.download_file(file.file_path)

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω–æ (–∏–ª–∏ –º–æ–∂–Ω–æ –≤ –ø–∞–º—è—Ç—å —Å BytesIO)
        temp_filename = f"temp_voice_{message.message_id}.ogg"
        with open(temp_filename, "wb") as f:
            f.write(downloaded_file.read())

        # –¢—Ä–∞–Ω—Å–∫—Ä–∏–ø—Ü–∏—è (–ø—Ä–∏–º–µ—Ä —Å faster-whisper)
        from faster_whisper import WhisperModel

        model = WhisperModel(
            "small"
        )  # –∏–ª–∏ "base", "medium" ‚Äî –≤ –∑–∞–≤–∏—Å–∏–º–æ—Å—Ç–∏ –æ—Ç —Ä–µ—Å—É—Ä—Å–æ–≤; "small" —Ö–æ—Ä–æ—à–æ –¥–ª—è —Ä—É—Å—Å–∫–æ–≥–æ
        segments, info = model.transcribe(
            temp_filename, language="ru"
        )  # —è–≤–Ω–æ —É–∫–∞–∑—ã–≤–∞–µ–º —Ä—É—Å—Å–∫–∏–π
        transcribed_text = " ".join(seg.text for seg in segments).strip()

        # –£–¥–∞–ª—è–µ–º –≤—Ä–µ–º–µ–Ω–Ω—ã–π —Ñ–∞–π–ª
        import os

        os.remove(temp_filename)

        if not transcribed_text:
            await placeholder.edit_text(
                "‚ö†Ô∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ –≥–æ–≤–æ—Ä–∏—Ç—å —á—ë—Ç—á–µ."
            )
            return

        await placeholder.edit_text(
            f"üé§ –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: {transcribed_text}\n\n‚è≥ –ì–µ–Ω–µ—Ä–∏—Ä—É—é –æ—Ç–≤–µ—Ç..."
        )

        # –¢–µ–ø–µ—Ä—å –∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ—Ç –∂–µ –∫–æ–¥ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏, —á—Ç–æ –∏ –¥–ª—è —Ç–µ–∫—Å—Ç–∞
        # –õ—É—á—à–µ –≤—ã–Ω–µ—Å—Ç–∏ –≤ –æ—Ç–¥–µ–ª—å–Ω—É—é —Ñ—É–Ω–∫—Ü–∏—é, –Ω–æ –¥–ª—è –ø—Ä–∏–º–µ—Ä–∞ –¥—É–±–ª–∏—Ä—É–µ–º –ª–æ–≥–∏–∫—É
        full_text = ""
        buffer_text = ""

        async def on_chunk(chunk: str):
            nonlocal full_text, buffer_text
            buffer_text += chunk
            if len(buffer_text) > 20:
                full_text += buffer_text
                try:
                    await placeholder.edit_text(full_text[:4000])
                except Exception:
                    pass
                buffer_text = ""
                await asyncio.sleep(0.1)

        await generate_stream(
            model=user["model"],
            system_prompt=user["system_prompt"],
            history=user["history"],
            user_prompt=transcribed_text,
            on_chunk=on_chunk,
        )

        full_text += buffer_text
        await placeholder.edit_text(full_text[:4000])

        # –°–æ—Ö—Ä–∞–Ω—è–µ–º –≤ –∏—Å—Ç–æ—Ä–∏—é (–≥–æ–ª–æ—Å–æ–≤–æ–µ –∫–∞–∫ —Ç–µ–∫—Å—Ç –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è)
        user["history"].append(
            {"role": "user", "content": f"[–ì–æ–ª–æ—Å–æ–≤–æ–µ] {transcribed_text}"}
        )
        user["history"].append({"role": "assistant", "content": full_text})

    except Exception as e:
        logging.exception("–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ")
        await placeholder.edit_text(f"‚ùå –û—à–∏–±–∫–∞: {e}")


# –û—Å–Ω–æ–≤–Ω–æ–π —á–∞—Ç
@router.message()
async def on_chat(message: types.Message):
    user = get_user(message.from_user.id)

    # –ï—Å–ª–∏ –∂–¥–µ–º –Ω–æ–≤—ã–π system prompt
    if user.get("waiting_for_prompt"):
        user["system_prompt"] = message.text
        user["waiting_for_prompt"] = False
        await message.answer("‚úÖ System prompt –æ–±–Ω–æ–≤–ª—ë–Ω.")
        return

    placeholder = await message.answer("‚è≥ –ì–µ–Ω–µ—Ä–∏—Ä—É—é...")

    full_text = ""
    buffer_text = ""

    # –ë—É—Ñ–µ—Ä–∏–∑–∏—Ä–æ–≤–∞–Ω–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è on_chunk
    async def on_chunk(chunk: str):
        nonlocal full_text, buffer_text
        buffer_text += chunk
        if len(buffer_text) > 20:
            full_text += buffer_text
            try:
                await placeholder.edit_text(full_text[:4000])
            except Exception:
                logging.exception("–ù–µ —É–¥–∞–ª–æ—Å—å –æ–±–Ω–æ–≤–∏—Ç—å —Å–æ–æ–±—â–µ–Ω–∏–µ")
            buffer_text = ""
            # –¥–∞—ë–º Telegram –Ω–µ–º–Ω–æ–≥–æ ‚Äú–æ—Ç–¥—ã—Ö–∞‚Äù
            await asyncio.sleep(0.1)

    try:
        await generate_stream(
            model=user["model"],
            system_prompt=user["system_prompt"],
            history=user["history"],
            user_prompt=message.text,
            on_chunk=on_chunk,
        )
    except Exception as e:
        await message.answer(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏: {e}")
        return

    # –û—Ç–ø—Ä–∞–≤–ª—è–µ–º –æ—Å—Ç–∞–≤—à–∏–π—Å—è –±—É—Ñ–µ—Ä
    full_text += buffer_text
    try:
        await placeholder.edit_text(full_text[:4000])
    except Exception:
        pass

    # –°–æ—Ö—Ä–∞–Ω—è–µ–º –∏—Å—Ç–æ—Ä–∏—é
    user["history"].append({"role": "user", "content": message.text})
    user["history"].append({"role": "assistant", "content": full_text})
